- [Горутины](#горутины)
  - [Описание проблемы](#описание-проблемы)
  - [Решение в golang](#решение-в-golang)
  - [Модель MGP](#модель-mgp)
  - [Network poller](#network-poller)

# Горутины

## Описание проблемы

Программы на golang, как и программы на других ЯП, 
запускаются на компьютерах: реальных (ноутбук, baremetal сервер)
и виртуальных (LXC или docker-контейнер, или pod k8s).

Программа запускается не напрямую на компьютере, а под управлением ОС. 
Именно ОС управляет жизненным циклом приложения и устанавливает правила, 
по которым приложения получают возможность задействовать ядра процессоров.

Для этого ОС использует абстракцию, которая называется `потоки`. 
Код приложения выполняется в одном или нескольких потоках, которые
по определённым правилам получают доступ к ядрам CPU.

Во всех основных типах современных ОС (win, mac, linux) используется 
**вытесняющий планировщик потоков**. Это означает, что только ОС
принимает решение, когда выдать для определённого потока 
доступ к определённому ядру CPU, и когда этот доступ у потока забрать
и отдать другому потоку. Другой подход к решению задачи управления
потоками -- кооперативный планировщик, в котором потоки сами решают,
когда освобождать занятное им ядро. Но при таком подходе, отдельные
приложения могут забирать себе все ресурсы и не давать выполняться
другим приложениям, поэтому в современных ОС его не применяют.

В вытесняющем планировщике поток может находиться в 1 из 3 состояний:

- ожидание
- готовность к выполнению
- выполнение

Если поток находится в статусе **выполнение**, это значит, 
что ОС предоставила ему доступ к определённому ядру, и поток
выполняет на этом ядре свой код.

В любой момент времени (нет возможности управлять этим) ОС может
прервать выполнение потока и передать ядро другому потоку. Поток,
у которого забрали доступ к ядру, переходит в статус **готовность к выполнению**.

Если ОС обслуживает больше потоков, чем доступно ядер CPU, 
то выполняющиеся потоки будут **конкурировать** за ядра,
потому что ОС будет их переключать.

В некоторых случаях ОС может останавливать поток не для того,
чтобы передать ядро другому потоку, а по причине того, 
что поток ждёт чего-то, прежде чем сможет продолжить. 
Причины перевода поток в статус **ожидание**:

- синхронные системные вызовы
- вызовы системных примитивов синхронизации (e.g., мьютексы или атомарные процессорные операции)
- аппаратное ожидание (сеть или диск)

Итак, ОС может переключать потоки по 2 причинам:

1. Равномерное распределение ресурсов CPU, когда потоков больше, чем ядер.
2. Когда поток сам совершает такие операции, которые подразумевают переход его в ожидание (блокирующие операции).

Когда ОС переключает потоки, ей требуется сохранить данные текущего потока, 
чтобы потом была возможность продолжить его выполнение. Эта операция называется
переключение контекста. Переключение контекста -- дорогостоящая операция, 
на современном железе она занимает примерно 1.5 мкс. 

**Основная проблема субоптимальной (плохой) производительности 
многопоточных приложений -- переключение контекста чаще, чем нужно**.

Для оптимизации использования ресурсов приложениями, 
можно выделить 2 подхода:

1. Ограничивать общее количество потоков, которые обслуживает ОС на данном компьютере.
Это не относится к разработке приложений на конкретном ЯП, но в целом можно и нужно
ограничивать как количество запускаемых на ОС приложений, так и количество потоков, 
которые они порождают.

2. Избегать слишком частого переключения контекста из-за блокирующих операций.

Рантайм golang содержит ряд оптимизаций, основная цель которых -- 
**избежать слишком частого переключения контекста из-за блокирующих операций**.

## Решение в golang

Разработчики golang сосредоточились на решении проблемы слишком частого переключения контекста
из-за блокирующих операций. Приложения на golang вообще лишены доступа к потокам уровня ОС;
вместо этого, рантайм предоставляет **виртуальные потоки уровня приложения** -- горутины.

Код приложения особым образом (с помощью ключевого слова `go`) сообщает рантайму,
что эту функцию необходимо запустить в отдельном виртуальном потоке. 
Субъектом запуска отдельного виртуального потока является функция, то есть,
**горутина -- это просто функция**. Входная точка любого приложения 
на golang -- функция `main` в пакете с таким же именем -- тоже горутина.

Итак, запуск любого приложения на golang порождает несколько виртуальных потоков (горутин):

1. Функция `main` пакета `main`.
2. Сборщик мусора (GC).
3. Network poller -- оптимизирует блокирующие вызовы, связанные с сетевым I/O.

Кроме этого, приложение может порождать другие горутины с помощью инструкции `go`.

Планировщик golang управляет горутинами, предоставляя им доступ к потоку ОС и 
отбирая этот доступ, как планировщик потоков ОС делает это с потоками приложений.
Планировщик golang не может вмешиваться к работу планировщика ОС; вместо этого, 
планировщик переключает выполнение различных горутин (виртуальных потоков), 
**используя для этого один поток ОС**.

Во многих ситуациях разные горутины могут работать с общими участками памяти
(когда мы передаём переменную по указателю), но следует понимать, что 
**у каждой горутины своя область стека**. Разделяемые данные передаются туда
в виде стековых переменных, в которых содержится адрес области из кучи 
(адрес -- это целое размером 4 или 8 байт).

В качестве итога можно сказать, что golang отличается от других языков 
только тем, как он оптимизирует работу приложения с потоками ОС:

1. Рантайм golang сам управляет запуском потоков ОС, а приложения этой возможности лишены.
2. Оптимизация возможна за счёт того, что каждый виртуальный поток работает со своей областью памяти.
Если одновременно хранить данные (стек) всех виртуальных потоков, то переключение виртуальных
потоков будет значительно быстрее переключения контекста на уровне ОС.
3. Оптимизация заключается в том, что несколько виртуальных потоков получают возможность
выполняться на общем треде ОС, используя дешёвое переключение виртуального контекста.

Важно понимать, что экономия на переключении контекста -- фактически единственное
преимущество golang перед другими языками. Если использовать его для других задач,
то преимущества не будет (golang в целом медленнее C) или оно будет не очень существенным.
К примеру, код на golang в целом производительнее кода на Python, но у Python есть другие
преимущества -- система типов, которая подходит для построения мощных абстракций (ORM).

Если от приложения не требуется высокой производительности, то может быть 
проще и дешевле разработать его на Python.

## Модель MGP

ОС управляет доступом к ядрам CPU с помощью абстракций-потоков, которыми управляет
планировщик уровня ОС.

Рантайм golang реализует аналогичный слой абстракции. Для этого вводятся следующие понятия:

- `G` (горутина) - виртуальный поток, может находиться в одном из 3 состояний
- `M` (машина) - потоки уровня ОС, на базе которых выполняются `G`
- `P` (процессор) - логический процессор, обычно ассоциируется с ядром процессора

Подобно тому, как потоки ОС могут находиться в одном из трёх статусов (ожидание, готовность и выполнение),
`G` тоже может находиться в одном из 3 состояний:

1. `waiting` -- G совершила блокирующую операцию.
2. `runnable` -- G может продолжить выполнение, но пока что она не выполняется в конкретном M.
3. `running` -- G выполняется на конкретном M до тех пор, пока не будет прервана планировщиком 
или не совершит блокирующую операцию.

По умолчанию, приложение на golang запускается с количеством `P`, равным количеству
виртуальных ядер CPU на компьютере. При необходимости можно изменить количество `P`.
Каждый `P` имеет свою (локальную) очередь горутин `G` в состоянии `runnable`. 
Эта очередь может быть пустой. Максимальная вместимость локальной очереди каждого `P`
составляет 256 `G`.

Планировщик порождает `M` по необходимости. Уже запущенные `M` не останавливаются,
а переиспользуются. `M` запускается на основе потоков ОС. По умолчанию, общее 
количество `M` в приложении ограничено числом 10 000.

В ходе своей работы, `M` связывается со свободным `P` (с которым не связаны другие `M`)
и выполняет горутины `G` из локальной очереди `P`. Если локальная очередь 
связанного `P` пуста, то `M` ищет горутины в состоянии `runnable`:

1. В локальных очередях других `P`.
2. В глобальной очереди выполнения.
3. В очереди network poller'а.

Если горутина `G`, выполняясь на `M` совершит блокирующую операцию, то планировщик 
переводит её в состояние `waiting`. В таком случае соответствующий `M` окажется заблокирован,
и планировщик отключит его от `P`. Если в локальной очереди `P` есть ещё
`G` в состоянии `runnable`, то планировщик выберет другой свободный `M`, или создаст новый.

## Network poller

Многопоточные приложения на любых ЯП могут сталкиваться с проблемами производительности,
если будет происходить частое переключение контекста из-за того, что потоки переходит 
в статус ожидания. 

Можно выделить две больших группы операций, вызывающих ожидание потока (блокирующих):

1. Использование примитивов синхронизации. Если возможно, то следует не использовать
синхронизацию, но во многих случаях без неё не обойтись. Перехода потока в статус ожидания
в таком случае нельзя избежать.
2. Использование блокирующих системных вызовов, например, операций сетевого или файлового ввода/вывода.

Современные ОС поддерживают мультиплексирование некоторых системных вызовов, в частности,
сетевых вызовов и, в отдельных случаях, файловых вызовов. Можно почитать, как это устроено
в POSIX-совместимых ОС:

- https://ps-group.github.io/os/nonblocking_io_posix
- https://www.opennet.ru/man.shtml?topic=epoll&category=4&russian=0

В рантайме golang реализован network poller, использующий механизм мультиплексирования 
системных вызовов, предоставляемый ОС. Если горутина `G` совершает системный вызов, 
для которого поддерживается мультиплексирование, то:

1. Планировщик переводит её в состояние `waiting` и переносит в очередь ожидания network poller'а.
2. Network poller совершает мультиплексированный системный вызов, помещая дескриптор в очередь и опрашивая его.
3. Когда определённый системный вызов завершается, соответствующая `G` удаляется из очереди ожидания 
network poller'а и переводится в статус `runnable`. Планировщик поместит её в одну из локальных очередей
процессоров `P` или в глобальную очередь ожидания. После чего, `G` продолжит выполнение на каком-либо
из `M`: либо при обработке своего `P`, либо в рамках work stealing.